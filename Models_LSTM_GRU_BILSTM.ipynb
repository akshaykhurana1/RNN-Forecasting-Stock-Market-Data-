{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm demonstrating Recurrent Neural Network for time-series and predictive analysis. Here, I'm using Gated Recurrent Unit(GRU), Long Short Term Memory(LSTM), and Bidirectional Long Short Term Memory(BiLSTM) for comparing their performances on NSE Tata stock market data. Then using the best model I'm predictions for next 5years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NSE Stock Market** data is used for study. The dataset exhibits daily stock prices from 2010 to 2018 including company's each day opening, closing, high, low, total quantity and  total turnover. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, QuantileTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Bidirectional, Activation, Dropout\n",
    "from keras import callbacks\n",
    "from keras.regularizers import l2\n",
    "from pandas import DataFrame\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.read_csv('Stock_Data.csv', parse_dates = ['Date'], index_col = 'Date')\n",
    "Dataset.head()\n",
    "df = Dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries (x_axis, y_axis, x_label, y_label):\n",
    "    plt.figure(figsize = (12, 7))\n",
    "    plt.plot(x_axis, y_axis, color ='black')\n",
    "    plt.xlabel(x_label, {'fontsize': 12}) \n",
    "    plt.ylabel(y_label, {'fontsize': 12})\n",
    "#     plt.savefig('E:/Forecast/1.jpg', format='jpg', dpi=1000)\n",
    "\n",
    "timeseries(df.index, df['Turnover_Lacs'], 'Time (day)','Turnover(Lacs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different plots to better understand the data and its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Open'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "sns.distplot(df['High'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "sns.distplot(df['Low'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "sns.distplot(df['Last'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "sns.distplot(df['Total_Trade_Quantity'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "sns.distplot(df['Turnover_Lacs'], hist = True, color = 'r')\n",
    "plt.show()\n",
    "\n",
    "sns_heat = sns.heatmap(df.corr(), annot = True)\n",
    "# plt.savefig('E:/Forecast/2.jpg', format='jpg', dpi=1000)\n",
    "sns_pair = sns.pairplot(df)\n",
    "# plt.savefig('E:/Forecast/3.jpg', format='jpg', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data distribution:\n",
    "\n",
    "fig, ax = plt.subplots(4,2, figsize=(16,16))\n",
    "sns.distplot(Dataset.Open, bins = 20, ax=ax[0,0]) \n",
    "sns.distplot(Dataset.High, bins = 20, ax=ax[0,1]) \n",
    "sns.distplot(Dataset.Low, bins = 20, ax=ax[1,0]) \n",
    "sns.distplot(Dataset.Last, bins = 20, ax=ax[1,1]) \n",
    "sns.distplot(Dataset.Close, bins = 20, ax=ax[2,0])\n",
    "sns.distplot(Dataset.Total_Trade_Quantity, bins = 20, ax=ax[2,1])\n",
    "sns.distplot(Dataset.Turnover_Lacs, bins = 20, ax=ax[3,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking outliers\n",
    "columns = list(Dataset.columns)[:-1]\n",
    "fig, ax = plt.subplots(4,2, figsize=(16,16))\n",
    "\n",
    "for idx, col in enumerate(columns):\n",
    "    sns.boxplot(data = Dataset, x = col, ax=ax[idx//2, idx % 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranforming the data using Quantile transformation\n",
    "X = Dataset.iloc[:, :]\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal')\n",
    "X_qt = qt.fit_transform(X)\n",
    "X_qt_df = pd.DataFrame(X_qt, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data distribution:\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize=(16,16))\n",
    "sns.distplot(X_qt_df.Open, bins = 20, ax=ax[0,0]) \n",
    "sns.distplot(X_qt_df.High, bins = 20, ax=ax[0,1]) \n",
    "sns.distplot(X_qt_df.Low, bins = 20, ax=ax[1,0]) \n",
    "sns.distplot(X_qt_df.Last, bins = 20, ax=ax[1,1]) \n",
    "sns.distplot(X_qt_df.Close, bins = 20, ax=ax[2,0])\n",
    "sns.distplot(X_qt_df.Total_Trade_Quantity, bins = 20, ax=ax[2,1])\n",
    "sns.distplot(X_qt_df.Turnover_Lacs, bins = 20, ax=ax[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+++++++++++++++++++++++++++++Splitting Data+++++++++++++++++++++++++++\n",
    "train_size = int(len(X_qt_df) * 0.75)\n",
    "print(train_size)\n",
    "training_data, testing_data = X_qt_df.iloc[:train_size], X_qt_df.iloc[train_size:]\n",
    "\n",
    "#+++++++++++++++++++++++Plotting Train and Test Data+++++++++++++++++++\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(training_data.Turnover_Lacs)\n",
    "plt.plot(testing_data.Turnover_Lacs)\n",
    "plt.xlabel('Time (day)')\n",
    "plt.ylabel('Turnover(Lacs)')\n",
    "plt.legend(['Train set', 'Test set'], loc='upper right')\n",
    "\n",
    "print('Dimension of Training Data: ',training_data.shape)\n",
    "print('Dimension of Testing Data: ', testing_data.shape)\n",
    "\n",
    "\n",
    "Train_X = training_data.drop('Turnover_Lacs', axis = 1)\n",
    "Train_Y = training_data.loc[:, ['Turnover_Lacs']]\n",
    "\n",
    "Test_X = testing_data.drop('Turnover_Lacs', axis = 1)\n",
    "Test_Y = testing_data.loc[:, ['Turnover_Lacs']]\n",
    "\n",
    "Train_X = Train_X.to_numpy()\n",
    "Train_Y = Train_Y.to_numpy()\n",
    "Test_X = Test_X.to_numpy()\n",
    "Test_Y = Test_Y.to_numpy()\n",
    "\n",
    "#+++++++++++++++++++++++Creating Dataset++++++++++++++++++++++++++++\n",
    "def create_dataset(X, y, time_steps = 1):\n",
    "    X_list, y_list = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:i + time_steps, :]\n",
    "        X_list.append(v)\n",
    "        y_list.append(y[i+time_steps])\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "Time_steps = 10\n",
    "\n",
    "X_train, y_train = create_dataset(Train_X, Train_Y, Time_steps)\n",
    "X_test, y_test = create_dataset(Test_X, Test_Y, Time_steps)\n",
    "\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_LSTM_model(m, units):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(m(units = units, input_shape = [X_train.shape[1], X_train.shape[2]], kernel_regularizer = l2(0.0001), return_sequences = True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(m(units = units))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "def create_BiLSTM_model(units):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = units, kernel_regularizer = l2(0.0001),return_sequences=True),input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Bidirectional(LSTM(units = units)))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model_gru = create_GRU_LSTM_model(GRU, 64)\n",
    "model_lstm = create_GRU_LSTM_model(LSTM, 64)\n",
    "model_bilstm = create_BiLSTM_model(64)\n",
    "\n",
    "def fit_model(model):\n",
    "    early_stop = callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "    history = model.fit(X_train, y_train, epochs = 400, validation_split = 0.2, batch_size = 32, shuffle = False, callbacks = [early_stop])\n",
    "    return history\n",
    "\n",
    "history_gru = fit_model(model_gru)\n",
    "history_lstm = fit_model(model_lstm)\n",
    "history_bilstm = fit_model(model_bilstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train loss and validation loss\n",
    "def plot_loss (history):\n",
    "    plt.figure(figsize = (15, 9))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
    "\n",
    "plot_loss (history_bilstm)\n",
    "plot_loss (history_lstm)\n",
    "plot_loss (history_gru)\n",
    "\n",
    "def prediction(model):\n",
    "    prediction = model.predict(X_test)\n",
    "    return prediction\n",
    "\n",
    "prediction_bilstm = prediction(model_bilstm)\n",
    "prediction_lstm = prediction(model_lstm)\n",
    "prediction_gru = prediction(model_gru)\n",
    "\n",
    "\n",
    "# Plot true future vs prediction\n",
    "def plot_future(prediction, y_test):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label='True Future')     \n",
    "    plt.plot(np.arange(range_future),np.array(prediction),label='Prediction')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time (day)')\n",
    "    plt.ylabel('Turnover(Lacs)')\n",
    "    #plt.savefig('E:/Forecast/4.jpg', format='jpg', dpi=1000)\n",
    "    \n",
    "plot_future(prediction_bilstm, y_test)\n",
    "plot_future(prediction_lstm, y_test)\n",
    "plot_future(prediction_gru, y_test)\n",
    "\n",
    "def evaluate_prediction(predictions, actual, model_name):\n",
    "    errors = predictions - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print(model_name + ':')\n",
    "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
    "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
    "    print('')\n",
    "evaluate_prediction(prediction_bilstm, y_test, 'Bidirectional LSTM')\n",
    "evaluate_prediction(prediction_lstm, y_test, 'LSTM')\n",
    "evaluate_prediction(prediction_gru, y_test, 'GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Future Predictions on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Unseen Data\n",
    "newinput = pd.read_csv('Test_Data.csv', parse_dates=['Date'], index_col = 'Date')\n",
    "#Sorting to maintain the order of data\n",
    "newinput.sort_index(inplace=True)\n",
    "newinput.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histoy and future data\n",
    "def plot_history_future(y_train, prediction, model_name):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    range_history = len(y_train)\n",
    "    range_future = list(range(range_history, range_history + len(prediction)))\n",
    "\n",
    "    plt.plot(np.arange(range_history), np.array(y_train), label='History')\n",
    "    plt.plot(range_future, np.array(prediction),label='Prediction')\n",
    "\n",
    "    plt.title('History and prediction for ' + model_name)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time (day)')\n",
    "    plt.ylabel('TurnOver Lacs')\n",
    "    #plt.savefig('C:/Users/nious/Documents/Medium/LSTM&GRU/3.jpg', format='jpg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_steps = 10\n",
    "def forecast(X_input, time_steps):\n",
    "    # Scale the unseen input with the scaler fitted on the training data\n",
    "    X = qt.fit_transform(X_input)\n",
    "    X = pd.DataFrame(X,columns=newinput.columns)\n",
    "    X = X.drop('Turnover_Lacs', axis = 1)\n",
    "    Y = newinput.loc[:, ['Turnover_Lacs']]\n",
    "    y_transform = qt.fit_transform(Y)\n",
    "    X = X.to_numpy()\n",
    "    Xs = []\n",
    "\n",
    "    # Reshape unseen data to a 3D input\n",
    "    def create_dataset(X,time_steps = 1):\n",
    "        Xs = []\n",
    "        for i in range(len(X) - time_steps):\n",
    "            v = X[i:i + time_steps, :]\n",
    "            Xs.append(v)\n",
    "        return np.array(Xs)\n",
    "    X_transformed = create_dataset(X, Time_steps)\n",
    "\n",
    "    # Make prediction for unseen data using LSTM model \n",
    "    prediction = model_lstm.predict(X_transformed)\n",
    "    return prediction\n",
    "\n",
    "prediction = forecast(newinput, Time_steps)\n",
    "plot_history_future(y_train, prediction,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
